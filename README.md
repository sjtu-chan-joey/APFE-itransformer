# APFE-itransformer

**APFE-iTransformer** (Adaptive Pruning Frequency Enhanced iTransformer) is a robust and efficient framework for multivariate time-series forecasting, tailored for noisy and complex environments such as spacecraft telemetry systems. This is the official implementation of our method proposed in:

> ğŸ“„ **APFE-iTransformer: Adaptive Frequency-Domain Pruning Enhanced iTransformer for Multivariate Time-Series Forecasting**  
> âœï¸ Authors: [Author List]  
> ğŸ·ï¸ Venue: [Conference or Journal, Year]  
> ğŸ“ [Link to Paper if available]
![image](https://github.com/sjtu-chan-joey/APFE-itransformer/blob/main/figs/itrans.png)

---

## ğŸ” Overview

APFE-iTransformer addresses two major challenges in time-series forecasting:

- Modeling **long-term temporal dependencies**
- Adapting to **channel-specific noise and spectral redundancy**

It integrates:
- âœ… Legendre Memory Units (LMU) for compact long-term history encoding
  ![image](https://github.com/sjtu-chan-joey/APFE-itransformer/blob/main/figs/Legendre.png)
- âœ… Adaptive Top-$k$ Frequency Pruning for denoising
  ![image](https://github.com/sjtu-chan-joey/APFE-itransformer/blob/main/figs/AFPE.png)
- âœ… Inverted Transformer architecture for subsystem-level attention

---

## âœ¨ Key Features

- ğŸ”„ **Channel-inverted attention**: Models inter-variable dependencies across spacecraft subsystems
- ğŸ§  **Legendre projection**: Captures long-term memory in a compressed orthogonal basis
- ğŸ¯ **Frequency-domain pruning**: Retains only the most predictive harmonics per channel
- âš¡ **Fast runtime**: Load time â‰¤ 18s with competitive accuracy  
- ğŸ“ˆ **State-of-the-art performance** on Martian power prediction tasks

---

```
@article{your2024apfe,
  title={APFE-iTransformer: Adaptive Frequency-Domain Pruning Enhanced iTransformer for Multivariate Time-Series Forecasting},
  author={Your Name and Collaborators},
  journal={...},
  year={2024}
}
```

